{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b91473d-72ed-417e-aa71-3085cae132f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Macroni n Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Uttapam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Cereals-Corn Flakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Idli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Berries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Cashew Nuts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Protein Powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Chia seeds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Food_items\n",
       "187    Macroni n Cheese \n",
       "328              Uttapam\n",
       "75   Cereals-Corn Flakes\n",
       "169                 Idli\n",
       "41               Berries\n",
       "73           Cashew Nuts\n",
       "251       Protein Powder\n",
       "82            Chia seeds"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "file_path = 'foodrecmergedallergen.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Normalize Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X_numerical = scaler.fit_transform(data[['Calories', 'Fats', 'Proteins', 'Iron', 'Calcium', 'Sodium', 'Potassium', 'Carbohydrates', 'Fibre', 'VitaminD', 'Sugars']])\n",
    "\n",
    "# Train KNN Model\n",
    "knn = NearestNeighbors(n_neighbors=9, metric='euclidean')\n",
    "knn.fit(X_numerical)\n",
    "\n",
    "\n",
    "def recommend_recipes(input_features, user_allergy):\n",
    "    # Scale the numerical features\n",
    "    input_features_scaled = scaler.transform([input_features])\n",
    "    \n",
    "    # Get KNN recommendations\n",
    "    distances, indices = knn.kneighbors(input_features_scaled)\n",
    "    recommendations = data.iloc[indices[0]]\n",
    "    filtered_recommendations = recommendations[~recommendations['Food_allergy'].str.contains(user_allergy, case=False, na=False)]\n",
    "    return filtered_recommendations[['Food_items']]\n",
    "input_features = [540, 16, 10,400,10,7,90,80,10,2,90]\n",
    "recommendations = recommend_recipes(input_features,'Gluten')\n",
    "recommendations\n",
    "#this is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9be69d13-3d72-4751-9057-f74ccc299d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\AppData\\Local\\Temp\\ipykernel_22928\\2366502366.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  recipe_df['Food_allergy'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'foodrecmergedallergen.xlsx'\n",
    "recipe_df = pd.read_excel(file_path)\n",
    "\n",
    "# Example User Allergy List\n",
    "user_allergies = ['Gluten']  # Replace with actual user allergies\n",
    "\n",
    "# Fill NaN values in 'Food_allergy' with 'Unknown'\n",
    "recipe_df['Food_allergy'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Feature extraction for ingredients and nutritional values\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_ingredients = vectorizer.fit_transform(recipe_df['Food_items'])\n",
    "\n",
    "# Normalize Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X_numerical = scaler.fit_transform(recipe_df[['Calories', 'Fats', 'Proteins', 'Iron', 'Calcium', 'Sodium', 'Potassium', 'Carbohydrates', 'Fibre', 'VitaminD', 'Sugars']])\n",
    "\n",
    "# Combine Features\n",
    "X_combined = np.hstack([X_numerical, X_ingredients.toarray()])\n",
    "y = recipe_df['Food_allergy']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "# smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "# X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train KNN Classifier Model\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10, metric='euclidean') #57%accuracy\n",
    "#knn_classifier = KNeighborsClassifier(n_neighbors=5, metric='manhattan', weights='distance') 63% accuracy\n",
    "\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "print(f\"KNN Model Accuracy: {knn_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0abff01-a3d1-43ee-80bd-3340d21c4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food_allergy\n",
      "Unknown                                  172\n",
      "Dairy                                     53\n",
      "Gluten                                    38\n",
      "Dairy, Gluten                             33\n",
      "Soy                                        7\n",
      "Shellfish                                  6\n",
      "Gluten, Dairy                              4\n",
      "Dairy, Gluten (pasta)                      3\n",
      "Fish                                       3\n",
      "Nuts (if pesto contains nuts)              2\n",
      "Nuts (if pesto contains nuts), Gluten      2\n",
      "Dairy, Gluten (wrap)                       2\n",
      "Nuts                                       1\n",
      "Nuts                                       1\n",
      "Nuts (Cashews)                             1\n",
      "Dairy, Gluten (noodles)                    1\n",
      "Garlic                                     1\n",
      "Dairy, Nuts (if cashews used)              1\n",
      "Dairy, Gluten (croutons)                   1\n",
      "Fish, Gluten                               1\n",
      "Eggs, Dairy, Gluten (bread)                1\n",
      "Dairy, Gluten (crust)                      1\n",
      "Dairy, Gluten (pita)                       1\n",
      "Gluten, Dairy (if cheese used)             1\n",
      "Gluten (bun)                               1\n",
      "Shellfish, Dairy                           1\n",
      "Shellfish, Dairy, Gluten (roll)            1\n",
      "Nuts (Peanuts)                             1\n",
      "Eggs, Dairy                                1\n",
      "Gluten (if not certified gluten-free)      1\n",
      "Nuts (Pecans), Gluten                      1\n",
      "Varies (check specific product)            1\n",
      "Shellfish, Gluten (pasta)                  1\n",
      "Fish, Gluten (bread)                       1\n",
      "Eggs                                       1\n",
      "Name: count, dtype: int64\n",
      "KNN Model Accuracy: 0.91\n",
      "Cross-validation scores: [0.92753623 0.88405797 0.9368932  0.96601942 0.9368932 ]\n",
      "Mean cross-validation accuracy: 0.93\n",
      "KNN indices: [[320 156 187 746 169]]\n",
      "              Food_items Food_allergy\n",
      "174    Lemon Dill Salmon      Unknown\n",
      "208        Mushroom Soup        Dairy\n",
      "189  Malai Chicken Tikka        Dairy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'foodrecmergedallergen.xlsx'\n",
    "recipe_df = pd.read_excel(file_path)\n",
    "\n",
    "# Example User Allergy List\n",
    "user_allergies = ['Gluten']  # Replace with actual user allergies\n",
    "\n",
    "# Fill NaN values in 'Food_allergy' with 'Unknown'\n",
    "recipe_df['Food_allergy'] = recipe_df['Food_allergy'].fillna('Unknown')\n",
    "\n",
    "# Check the class distribution\n",
    "print(recipe_df['Food_allergy'].value_counts())\n",
    "\n",
    "# Remove classes with very few samples (e.g., less than 5)\n",
    "min_class_count = 5  # Set the threshold for the minimum number of samples per class\n",
    "class_counts = recipe_df['Food_allergy'].value_counts()\n",
    "minority_classes = class_counts[class_counts < min_class_count].index\n",
    "recipe_df = recipe_df[~recipe_df['Food_allergy'].isin(minority_classes)]\n",
    "\n",
    "# Feature extraction for ingredients and nutritional values\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_ingredients = vectorizer.fit_transform(recipe_df['Food_items'])\n",
    "\n",
    "# Normalize Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X_numerical = scaler.fit_transform(recipe_df[['Calories', 'Fats', 'Proteins', 'Iron', 'Calcium', 'Sodium', 'Potassium', 'Carbohydrates', 'Fibre', 'VitaminD', 'Sugars']])\n",
    "\n",
    "# Combine Features\n",
    "X_combined = np.hstack([X_numerical, X_ingredients.toarray()])\n",
    "y = recipe_df['Food_allergy']\n",
    "\n",
    "# Apply SMOTE for class balancing (now should work as we've removed small classes)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=3)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_combined, y)\n",
    "\n",
    "# Apply PCA for dimensionality reduction (optional but can improve model performance)\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of the variance\n",
    "X_resampled = pca.fit_transform(X_resampled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train KNN Classifier Model with optimized hyperparameters\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, metric='manhattan', weights='distance')\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "print(f\"KNN Model Accuracy: {knn_accuracy:.2f}\")\n",
    "\n",
    "# Optionally, perform cross-validation to get a better estimate of accuracy\n",
    "cv_scores = cross_val_score(knn_classifier, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {cv_scores.mean():.2f}\")\n",
    "\n",
    "def recommend_recipes(input_features, user_allergy, scaler, vectorizer, knn_classifier, pca, recipe_df):\n",
    "    # Step 1: Extract and reshape the input nutritional data\n",
    "    nutritional_input = np.array(input_features).reshape(1, -1)  # Nutritional features (1 sample)\n",
    "    \n",
    "    # Step 2: Scale the nutritional features using the scaler (apply same scaling as during training)\n",
    "    nutritional_input_scaled = scaler.transform(nutritional_input)\n",
    "    \n",
    "    # Step 3: Combine with TF-IDF vector (assuming no ingredients are provided in input)\n",
    "    ingredients_input = vectorizer.transform(['']).toarray()  # Placeholder for ingredients (empty string or dummy)\n",
    "    \n",
    "    # Combine nutritional input and ingredient input\n",
    "    combined_input = np.hstack([nutritional_input_scaled, ingredients_input])\n",
    "    \n",
    "    # Step 4: Apply PCA transformation to match the PCA space used during training\n",
    "    combined_input_pca = pca.transform(combined_input)\n",
    "    \n",
    "    # Step 5: Ensure the PCA-transformed input is within valid range for KNN\n",
    "    # Here, combined_input_pca is a 1x33 array, corresponding to the number of components in PCA\n",
    "    # Now we can safely get KNN indices without worrying about out-of-bounds errors\n",
    "    \n",
    "    distances, indices = knn_classifier.kneighbors(combined_input_pca)\n",
    "    \n",
    "    # Debug: Check the indices returned by KNN\n",
    "    print(f\"KNN indices: {indices}\")\n",
    "    \n",
    "    # Step 6: Ensure indices are within bounds of the recipe DataFrame\n",
    "    valid_indices = [i for i in indices[0] if i < len(recipe_df)]  # Only keep valid indices within bounds\n",
    "    \n",
    "    if not valid_indices:\n",
    "        print(f\"Error: No valid indices found. Max index is {indices[0].max()}, but recipe_df has {len(recipe_df)} rows.\")\n",
    "        return None\n",
    "    \n",
    "    # Filter the recommendations using valid indices\n",
    "    recommendations = recipe_df.iloc[valid_indices]\n",
    "\n",
    "    # Step 7: Filter out recipes based on the user's allergy\n",
    "    filtered_recommendations = recommendations[~recommendations['Food_allergy'].str.contains(user_allergy, case=False, na=False)]\n",
    "\n",
    "    # Step 8: Return the filtered food items along with allergy information\n",
    "    return filtered_recommendations[['Food_items', 'Food_allergy']]\n",
    "\n",
    "# Example Input (Nutritional Features)\n",
    "# input_features = [500, 160, 1, 300, 110, 679, 8, 8, 1, 2, 90]  # Nutritional features (without ingredients)\n",
    "# user_allergy = 'Dairy'  # Allergy input from the user\n",
    "input_features = [540, 16, 10, 400, 10, 7, 90, 80, 10, 2, 90]  # Nutritional features\n",
    "user_allergy = 'Gluten'  # Allergy input from the user\n",
    "\n",
    "# Assuming 'scaler', 'vectorizer', 'knn_classifier', and 'pca' are already trained\n",
    "recommendations = recommend_recipes(input_features, user_allergy, scaler, vectorizer, knn_classifier, pca, recipe_df)\n",
    "print(recommendations)\n",
    "\n",
    "\n",
    "#KNN MODEL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8628596d-c0f0-410e-9382-66990e3d30f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food_allergy\n",
      "Unknown                                  172\n",
      "Dairy                                     53\n",
      "Gluten                                    38\n",
      "Dairy, Gluten                             33\n",
      "Soy                                        7\n",
      "Shellfish                                  6\n",
      "Gluten, Dairy                              4\n",
      "Dairy, Gluten (pasta)                      3\n",
      "Fish                                       3\n",
      "Nuts (if pesto contains nuts)              2\n",
      "Nuts (if pesto contains nuts), Gluten      2\n",
      "Dairy, Gluten (wrap)                       2\n",
      "Nuts                                       1\n",
      "Nuts                                       1\n",
      "Nuts (Cashews)                             1\n",
      "Dairy, Gluten (noodles)                    1\n",
      "Garlic                                     1\n",
      "Dairy, Nuts (if cashews used)              1\n",
      "Dairy, Gluten (croutons)                   1\n",
      "Fish, Gluten                               1\n",
      "Eggs, Dairy, Gluten (bread)                1\n",
      "Dairy, Gluten (crust)                      1\n",
      "Dairy, Gluten (pita)                       1\n",
      "Gluten, Dairy (if cheese used)             1\n",
      "Gluten (bun)                               1\n",
      "Shellfish, Dairy                           1\n",
      "Shellfish, Dairy, Gluten (roll)            1\n",
      "Nuts (Peanuts)                             1\n",
      "Eggs, Dairy                                1\n",
      "Gluten (if not certified gluten-free)      1\n",
      "Nuts (Pecans), Gluten                      1\n",
      "Varies (check specific product)            1\n",
      "Shellfish, Gluten (pasta)                  1\n",
      "Fish, Gluten (bread)                       1\n",
      "Eggs                                       1\n",
      "Name: count, dtype: int64\n",
      "Random Forest Model Accuracy: 0.95\n",
      "Random Forest Cross-validation scores: [0.94202899 0.92753623 0.97087379 0.98543689 0.96601942]\n",
      "Mean Random Forest cross-validation accuracy: 0.96\n",
      "Random Forest Prediction: Unknown\n",
      "Class Probabilities: [0.14 0.22 0.12 0.05 0.   0.47]\n",
      "Top 10 indices: [167  43 291  70 151 596  38  77 305 199]\n",
      "Recipe DataFrame size: 309\n",
      "              Food_items Food_allergy\n",
      "187    Macroni n Cheese       Unknown\n",
      "328              Uttapam      Unknown\n",
      "75   Cereals-Corn Flakes      Unknown\n",
      "169                 Idli      Unknown\n",
      "41               Berries      Unknown\n",
      "82            Chia seeds      Unknown\n",
      "343           White Rice      Unknown\n",
      "223        Oyster cooked      Unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import Random Forest\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'foodrecmergedallergen.xlsx'\n",
    "recipe_df = pd.read_excel(file_path)\n",
    "\n",
    "# Example User Allergy List\n",
    "user_allergies = ['Gluten']  # Replace with actual user allergies\n",
    "\n",
    "# Fill NaN values in 'Food_allergy' with 'Unknown'\n",
    "recipe_df['Food_allergy'] = recipe_df['Food_allergy'].fillna('Unknown')\n",
    "\n",
    "# Check the class distribution\n",
    "print(recipe_df['Food_allergy'].value_counts())\n",
    "\n",
    "# Remove classes with very few samples (e.g., less than 5)\n",
    "min_class_count = 5  # Set the threshold for the minimum number of samples per class\n",
    "class_counts = recipe_df['Food_allergy'].value_counts()\n",
    "minority_classes = class_counts[class_counts < min_class_count].index\n",
    "recipe_df = recipe_df[~recipe_df['Food_allergy'].isin(minority_classes)]\n",
    "\n",
    "# Feature extraction for ingredients and nutritional values\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_ingredients = vectorizer.fit_transform(recipe_df['Food_items'])\n",
    "\n",
    "# Normalize Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X_numerical = scaler.fit_transform(recipe_df[['Calories', 'Fats', 'Proteins', 'Iron', 'Calcium', 'Sodium', 'Potassium', 'Carbohydrates', 'Fibre', 'VitaminD', 'Sugars']])\n",
    "\n",
    "# Combine Features\n",
    "X_combined = np.hstack([X_numerical, X_ingredients.toarray()])\n",
    "y = recipe_df['Food_allergy']\n",
    "\n",
    "# Apply SMOTE for class balancing (now should work as we've removed small classes)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=3)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_combined, y)\n",
    "\n",
    "# Apply PCA for dimensionality reduction (optional but can improve model performance)\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of the variance\n",
    "X_resampled = pca.fit_transform(X_resampled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Classifier Model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # Random Forest with 100 trees\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using Random Forest\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for Random Forest\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Model Accuracy: {rf_accuracy:.2f}\")\n",
    "\n",
    "# Optionally, perform cross-validation to get a better estimate of accuracy for Random Forest\n",
    "rf_cv_scores = cross_val_score(rf_classifier, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "print(f\"Random Forest Cross-validation scores: {rf_cv_scores}\")\n",
    "print(f\"Mean Random Forest cross-validation accuracy: {rf_cv_scores.mean():.2f}\")\n",
    "\n",
    "\n",
    "def recommend_recipes(input_features, user_allergy, scaler, rf_classifier, pca, recipe_df):\n",
    "    # Step 1: Extract and reshape the input nutritional data\n",
    "    nutritional_input = np.array(input_features).reshape(1, -1)  # Nutritional features (no ingredients)\n",
    "    \n",
    "    # Step 2: Scale the nutritional features using the scaler (apply same scaling as during training)\n",
    "    nutritional_input_scaled = scaler.transform(nutritional_input)\n",
    "    \n",
    "    # Step 3: Create a dummy ingredient vector (e.g., an empty ingredient vector)\n",
    "    dummy_ingredient = np.zeros((1, X_ingredients.shape[1]))  # Create a dummy vector with zeros (no ingredients)\n",
    "    \n",
    "    # Step 4: Combine the nutritional features and the dummy ingredient vector\n",
    "    combined_input = np.hstack([nutritional_input_scaled, dummy_ingredient])\n",
    "    \n",
    "    # Step 5: Apply PCA transformation to match the PCA space used during training\n",
    "    combined_input_pca = pca.transform(combined_input)  # Transform using the combined input\n",
    "    \n",
    "    # Step 6: Predict using Random Forest classifier (getting the class probabilities for relevance)\n",
    "    rf_prediction = rf_classifier.predict(combined_input_pca)\n",
    "    rf_probabilities = rf_classifier.predict_proba(combined_input_pca)\n",
    "    \n",
    "    # Debug: Check the Random Forest Prediction and probabilities\n",
    "    print(f\"Random Forest Prediction: {rf_prediction[0]}\")\n",
    "    print(f\"Class Probabilities: {rf_probabilities[0]}\")\n",
    "    \n",
    "    # Step 7: Calculate the \"relevance\" of each food item to the input nutritional features\n",
    "    distances = np.linalg.norm(X_resampled - combined_input_pca, axis=1)  # Use resampled data (X_resampled)\n",
    "    \n",
    "    # Step 8: Sort food items by relevance (in this case, smallest distance)\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    \n",
    "    # Ensure that we do not exceed the bounds of the DataFrame\n",
    "    top_n = min(10, len(sorted_indices))  # Take the minimum of 10 or the available number of items\n",
    "    top_10_indices = sorted_indices[:top_n]\n",
    "    \n",
    "    # Debug: Check the top 10 indices to ensure they are valid\n",
    "    print(f\"Top 10 indices: {top_10_indices}\")\n",
    "    print(f\"Recipe DataFrame size: {recipe_df.shape[0]}\")\n",
    "    \n",
    "    # Ensure that indices are within bounds of recipe_df\n",
    "    top_10_indices = [i for i in top_10_indices if i < recipe_df.shape[0]]\n",
    "    \n",
    "    # Get the food items and allergies for the top 10\n",
    "    recommendations = recipe_df.iloc[top_10_indices]\n",
    "    \n",
    "    # Filter based on the user allergy\n",
    "    filtered_recommendations = recommendations[~recommendations['Food_allergy'].str.contains(user_allergy, case=False, na=False)]\n",
    "    \n",
    "    # Step 9: Return the filtered food items along with allergy information\n",
    "    return filtered_recommendations[['Food_items', 'Food_allergy']]\n",
    "\n",
    "# Example Input (Nutritional Features only, no ingredients)\n",
    "input_features = [540, 16, 10, 400, 10, 7, 90, 80, 10, 2, 90]  # Nutritional features\n",
    "user_allergy = 'Gluten'  # Allergy input from the user\n",
    "\n",
    "# Assuming 'scaler', 'rf_classifier', and 'pca' are already trained\n",
    "recommendations = recommend_recipes(input_features, user_allergy, scaler, rf_classifier, pca, recipe_df)\n",
    "print(recommendations)\n",
    "#random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6e609ee-da9e-4a10-8e3e-27f47e7cb6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Food_items\n",
      "187  Macroni n Cheese \n",
      "328            Uttapam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'foodrecmergedallergen.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Normalize Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X_numerical = scaler.fit_transform(data[['Calories', 'Fats', 'Proteins', 'Iron', 'Calcium', 'Sodium', 'Potassium', 'Carbohydrates', 'Fibre', 'VitaminD', 'Sugars']])\n",
    "\n",
    "# Apply KMeans Clustering (Choosing 5 clusters, but can be adjusted)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(X_numerical)\n",
    "\n",
    "def recommend_recipes(input_features, user_allergy):\n",
    "    # Step 1: Scale the input features using the previously fitted scaler\n",
    "    input_features_scaled = scaler.transform([input_features])\n",
    "    \n",
    "    # Step 2: Predict the cluster for the given input\n",
    "    input_cluster = kmeans.predict(input_features_scaled)[0]\n",
    "    \n",
    "    # Step 3: Get recipes from the same cluster\n",
    "    recommendations = data[data['Cluster'] == input_cluster]\n",
    "    \n",
    "    # Step 4: Filter out recipes containing the user's allergy\n",
    "    filtered_recommendations = recommendations[~recommendations['Food_allergy'].str.contains(user_allergy, case=False, na=False)]\n",
    "    \n",
    "    # Step 5: Return the food items in the filtered recommendations\n",
    "    return filtered_recommendations[['Food_items']]\n",
    "\n",
    "# Example Input Features (Nutritional values)\n",
    "input_features = [540, 16, 10, 400, 10, 7, 90, 80, 10, 2, 90]\n",
    "user_allergy = 'Gluten'  # Allergy to filter out\n",
    "\n",
    "# Get recommendations based on the input features and allergy\n",
    "recommendations = recommend_recipes(input_features, user_allergy)\n",
    "\n",
    "# Display the recommended recipes\n",
    "print(recommendations)\n",
    "#kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a26b5ba-2322-4c44-bdb0-86d7d658443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the clustering-based recommendation system: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\molly\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'foodrecmergedallergen.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Normalize Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X_numerical = scaler.fit_transform(data[['Calories', 'Fats', 'Proteins', 'Iron', 'Calcium', 'Sodium', 'Potassium', 'Carbohydrates', 'Fibre', 'VitaminD', 'Sugars']])\n",
    "\n",
    "# Apply KMeans Clustering (Choosing 5 clusters, but can be adjusted)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(X_numerical)\n",
    "\n",
    "def recommend_recipes(input_features, user_allergy):\n",
    "    # Step 1: Scale the input features using the previously fitted scaler\n",
    "    input_features_scaled = scaler.transform([input_features])\n",
    "    \n",
    "    # Step 2: Predict the cluster for the given input\n",
    "    input_cluster = kmeans.predict(input_features_scaled)[0]\n",
    "    \n",
    "    # Step 3: Get recipes from the same cluster\n",
    "    recommendations = data[data['Cluster'] == input_cluster]\n",
    "    \n",
    "    # Step 4: Filter out recipes containing the user's allergy\n",
    "    filtered_recommendations = recommendations[~recommendations['Food_allergy'].str.contains(user_allergy, case=False, na=False)]\n",
    "    \n",
    "    # Step 5: Return the food items in the filtered recommendations\n",
    "    return filtered_recommendations[['Food_items']], input_cluster\n",
    "\n",
    "def calculate_accuracy(input_features_list, user_allergy):\n",
    "    predicted_clusters = []\n",
    "    true_clusters = []\n",
    "    \n",
    "    # Loop over input features\n",
    "    for input_features in input_features_list:\n",
    "        recommendations, predicted_cluster = recommend_recipes(input_features, user_allergy)\n",
    "        \n",
    "        # Get the actual cluster from the dataset by using the KMeans model\n",
    "        actual_cluster = kmeans.predict([input_features])[0]  # Predict cluster for input features\n",
    "        \n",
    "        predicted_clusters.append(predicted_cluster)\n",
    "        true_clusters.append(actual_cluster)\n",
    "    \n",
    "    # Check for NaN values in true_clusters or predicted_clusters and remove them\n",
    "    valid_indices = ~np.isnan(true_clusters) & ~np.isnan(predicted_clusters)\n",
    "    true_clusters = np.array(true_clusters)[valid_indices]\n",
    "    predicted_clusters = np.array(predicted_clusters)[valid_indices]\n",
    "    \n",
    "    # Calculate accuracy by comparing predicted clusters with true clusters\n",
    "    if len(true_clusters) > 0:  # Only calculate accuracy if there are valid entries\n",
    "        accuracy = accuracy_score(true_clusters, predicted_clusters)\n",
    "        return accuracy\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Example Input Features (Nutritional values)\n",
    "input_features_list = [\n",
    "    [540, 16, 10, 400, 10, 7, 90, 80, 10, 2, 90],\n",
    "    [300, 20, 15, 300, 8, 4, 70, 60, 8, 1, 85],\n",
    "    # Add more input features here as needed for testing\n",
    "]\n",
    "\n",
    "user_allergy = 'Gluten'  # Allergy to filter out\n",
    "\n",
    "# Calculate accuracy for the given input features\n",
    "accuracy = calculate_accuracy(input_features_list, user_allergy)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy of the clustering-based recommendation system: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad656ed8-8eed-4346-ba4e-6d0db827b623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
